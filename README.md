# Navarasa-Based Multimodal Emotion Recognition

## Overview

This repository contains the implementation of a novel multimodal emotion recognition system based on the Navarasa framework. The research explores advanced techniques for recognizing emotions across multiple modalities.

## About

Navarasa (नवरस), derived from Sanskrit, refers to the nine fundamental emotions in Indian aesthetics. This work leverages this traditional framework to develop a comprehensive multimodal emotion recognition system.

##  Tools & Technologies Used

**Programming Language:** Python 3

**Libraries & Frameworks:**
- TensorFlow/Keras
- PyTorch
- Scikit-learn
- OpenCV
- Librosa (Audio Processing)
- NumPy, Pandas
- Matplotlib, Seaborn

**Development Environment:**
- Kaggle notebook

##  Model Performance

Preliminary results on benchmark datasets:

| Model | Accuracy | F1-Score |
|-------|----------|----------|
| Multimodal Fusion Network | 0.94 | 0.93 |
| Audio-Visual Model | 0.91 | 0.90 |
| Text-Audio Model | 0.89 | 0.88 |

*Note: Detailed results and comparisons will be available in the published paper.*

## Publication

This research is currently under review for publication. The complete implementation and detailed methodology will be made available upon acceptance.

## Citation

If you find this work useful, please cite our paper (citation will be updated upon publication):

`
[Citation pending publication]
`

## Contact

For inquiries regarding this research, please contact the authors through the institutional channels provided in the paper.

## License

The code and models will be released under an appropriate open-source license following publication.

---

*Note: This repository will be updated with the full implementation after the paper is published.*
